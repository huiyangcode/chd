{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "\n",
    "\n",
    "data = pd.read_csv(r\"newdata_coronary_health_step3.csv\",error_bad_lines=False)\n",
    "\n",
    "data = data[['年龄', '齿列_sum', '平均收缩压', 'WHtR',\n",
    "             '心电图label', '性别', '空腹血糖', '症状_sum',\n",
    "             '血小板', '体温','血尿素氮',\n",
    "             'label','local']]\n",
    "\n",
    "data_train = data[data['local']!=5.0]\n",
    "data_External = data[data['local']==5.0]\n",
    "data = data_train\n",
    "data.drop(['local',],axis = 1,inplace = True)\n",
    "\n",
    "data.rename(columns=({'年龄':'Age','齿列_sum':'Dentition', '平均收缩压':'MSP','WHtR':'WHtR',\n",
    "                    '心电图label':'ECG','空腹血糖':'FBG','症状_sum':'Symptom',\n",
    "                       '血小板': 'Thrombocyte','体温':'BT', \n",
    "                      '血尿素氮':'BUN',  }), inplace = True) \n",
    "\n",
    "\n",
    "mdata = data[data['gender']==1.0]\n",
    "fedata = data[data['gender']==2.0]\n",
    "\n",
    "mdata_External = data_External[data_External['gender']==1.0]\n",
    "fedata_External = data_External[data_External['gender']==2.0]\n",
    "\n",
    "mdata_External.rename(columns=({'年龄':'Age','齿列_sum':'Dentition', '平均收缩压':'MSP','WHtR':'WHtR',\n",
    "                    '心电图label':'ECG','空腹血糖':'FBG','症状_sum':'Symptom',\n",
    "                       '血小板': 'Thrombocyte','体温':'BT', \n",
    "                      '血尿素氮':'BUN',  }), inplace = True) \n",
    "\n",
    "# 模型，粗略跑一下查看结果\n",
    "X = mdata.iloc[:,mdata.columns != \"label\"]\n",
    "y = mdata.iloc[:,mdata.columns == \"label\"]\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler() \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.DataFrame(y)\n",
    "\n",
    "X_train, X_vali, Y_train, Y_vali = train_test_split(X,y,test_size=0.3,random_state=420)\n",
    "model_data = pd.concat([Y_train, X_train], axis=1)\n",
    "\n",
    "\n",
    "model_data.index = range(model_data.shape[0])\n",
    "\n",
    "\n",
    "\n",
    "vali_data = pd.concat([Y_vali, X_vali], axis=1)\n",
    "vali_data.index = range(vali_data.shape[0])\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "def graphforbestbin(name,DF, X, Y, n,q=20,graph=True):\n",
    "\n",
    "    \n",
    "    DF = DF[[X,Y]].copy()\n",
    "\n",
    "    DF[\"qcut\"],bins = pd.qcut(DF[X], retbins=True, q=q,duplicates=\"drop\")\n",
    "    coount_y0 = DF.loc[DF[Y]==0].groupby(by=\"qcut\").count()[Y]\n",
    "    coount_y1 = DF.loc[DF[Y]==1].groupby(by=\"qcut\").count()[Y]\n",
    "    num_bins = [*zip(bins,bins[1:],coount_y0,coount_y1)]\n",
    "\n",
    "    for i in range(q):\n",
    "        if 0 in num_bins[0][2:]:\n",
    "            num_bins[0:2] = [(\n",
    "                num_bins[0][0],\n",
    "                num_bins[1][1],\n",
    "                num_bins[0][2]+num_bins[1][2],\n",
    "                num_bins[0][3]+num_bins[1][3])]\n",
    "            continue\n",
    "\n",
    "        for i in range(len(num_bins)):\n",
    "            if 0 in num_bins[i][2:]:\n",
    "                num_bins[i-1:i+1] = [(\n",
    "                    num_bins[i-1][0],\n",
    "                    num_bins[i][1],\n",
    "                    num_bins[i-1][2]+num_bins[i][2],\n",
    "                    num_bins[i-1][3]+num_bins[i][3])]\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    def get_woe(num_bins):\n",
    "        columns = [\"min\",\"max\",\"count_0\",\"count_1\"]\n",
    "        df = pd.DataFrame(num_bins,columns=columns)\n",
    "        df[\"total\"] = df.count_0 + df.count_1\n",
    "        df[\"percentage\"] = df.total / df.total.sum()\n",
    "        df[\"bad_rate\"] = df.count_1 / df.total\n",
    "        df[\"good%\"] = df.count_0/df.count_0.sum()\n",
    "        df[\"bad%\"] = df.count_1/df.count_1.sum()\n",
    "        df[\"woe\"] = np.log(df[\"good%\"] / df[\"bad%\"])\n",
    "        return df\n",
    "\n",
    "    def get_iv(df):\n",
    "        rate = df[\"good%\"] - df[\"bad%\"]\n",
    "        iv = np.sum(rate * df.woe)\n",
    "        return iv\n",
    "\n",
    "    IV = []\n",
    "    axisx = []\n",
    "    while len(num_bins) > n:\n",
    "        pvs = []\n",
    "        for i in range(len(num_bins)-1):\n",
    "            x1 = num_bins[i][2:]\n",
    "            x2 = num_bins[i+1][2:]\n",
    "            pv = scipy.stats.chi2_contingency([x1,x2])[1]\n",
    "            pvs.append(pv)\n",
    "\n",
    "        i = pvs.index(max(pvs))\n",
    "        num_bins[i:i+2] = [(\n",
    "            num_bins[i][0],\n",
    "            num_bins[i+1][1],\n",
    "            num_bins[i][2]+num_bins[i+1][2],\n",
    "            num_bins[i][3]+num_bins[i+1][3])]\n",
    "\n",
    "        bins_df = pd.DataFrame(get_woe(num_bins))\n",
    "        axisx.append(len(num_bins))\n",
    "        IV.append(get_iv(bins_df))\n",
    "        \n",
    "    if graph:\n",
    "        plt.figure(figsize=(10,7), dpi= 500)\n",
    "        bwith = 1.5\n",
    "        TK = plt.gca()\n",
    "        TK.spines['bottom'].set_linewidth(bwith)\n",
    "        TK.spines['left'].set_linewidth(bwith)\n",
    "        TK.spines['top'].set_linewidth(bwith)\n",
    "        TK.spines['right'].set_linewidth(bwith)\n",
    "        plt.plot(axisx,IV,label=str(name),linewidth = 3.0)\n",
    "        font2 = {'family' : 'Times New Roman',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 25,\n",
    "        'style':'italic'\n",
    "        }\n",
    "        font1 = {'family' : 'Times New Roman',\n",
    "        'weight' : 'normal',\n",
    "        'size' : 16,\n",
    "        }\n",
    "        plt.xlabel('number of box',font2)\n",
    "        plt.ylabel(str(name)+\"_IV\",font2)\n",
    "\n",
    "        l1 = plt.legend(loc=\"lower right\",fontsize = 16,prop=font1)\n",
    "        plt.xticks(axisx)\n",
    "        plt.xlabel(\"number of box\")\n",
    "        plt.ylabel(str(name)+\"_IV\")\n",
    "        plt.show()\n",
    "\n",
    "    return bins_df\n",
    "\n",
    "model_data.columns\n",
    "\n",
    "column=[ 'Age', 'MSP', 'WHtR','FBG','Thrombocyte','BT', 'BUN', ]#d2\n",
    "\n",
    "for i in column[0:]:\n",
    "    print(i)\n",
    "    graphforbestbin(i,model_data,i,\"label\",n=2,q=20)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import scipy.stats as st\n",
    "\n",
    "def auto_bin(DF, X, Y, n, iv=True, detail=False,q=20):\n",
    "\n",
    "\n",
    "    DF = DF[[X,Y]].copy()\n",
    "\n",
    "\n",
    "    DF[\"qcut\"],bins = pd.qcut(DF[X], retbins=True, q=q, duplicates=\"drop\")\n",
    "\n",
    "    coount_y0 = DF.loc[DF[Y]==0].groupby(by=\"qcut\")[Y].count()\n",
    "    coount_y1 = DF.loc[DF[Y]==1].groupby(by=\"qcut\")[Y].count()\n",
    "\n",
    "    num_bins = [*zip(bins,bins[1:],coount_y0,coount_y1)]\n",
    "\n",
    "\n",
    "    def get_woe(num_bins):\n",
    "\n",
    "        columns = [\"min\",\"max\",\"count_0\",\"count_1\"]\n",
    "        df = pd.DataFrame(num_bins,columns=columns)\n",
    "\n",
    "        df[\"total\"] = df.count_0 + df.count_1\n",
    "        df[\"percentage\"] = df.total / df.total.sum()\n",
    "        df[\"bad_rate\"] = df.count_1 / df.total\n",
    "        df[\"woe\"] = np.log((df.count_0/df.count_0.sum()) /\n",
    "                           (df.count_1/df.count_1.sum()))\n",
    "        return df\n",
    "\n",
    "    def get_iv(bins_df):\n",
    "        rate = ((bins_df.count_0/bins_df.count_0.sum()) -\n",
    "                (bins_df.count_1/bins_df.count_1.sum()))\n",
    "        IV = np.sum(rate * bins_df.woe)\n",
    "        return IV\n",
    "\n",
    "\n",
    "    for i in range(20): \n",
    "\n",
    "        if 0 in num_bins[0][2:]:\n",
    "            num_bins[0:2] = [(\n",
    "                num_bins[0][0],\n",
    "                num_bins[1][1],\n",
    "                num_bins[0][2]+num_bins[1][2],\n",
    "                num_bins[0][3]+num_bins[1][3])]\n",
    "            continue\n",
    "\n",
    "\n",
    "        for i in range(len(num_bins)):\n",
    "            if 0 in num_bins[i][2:]:\n",
    "                num_bins[i-1:i+1] = [(\n",
    "                    num_bins[i-1][0],\n",
    "                    num_bins[i][1],\n",
    "                    num_bins[i-1][2]+num_bins[i][2],\n",
    "                    num_bins[i-1][3]+num_bins[i][3])]\n",
    "                break\n",
    "\n",
    "        else:\n",
    "            break\n",
    "\n",
    "\n",
    "    while len(num_bins) > n:\n",
    "\n",
    "        pvs = []\n",
    "        for i in range(len(num_bins)-1):\n",
    "            x1 = num_bins[i][2:]\n",
    "            x2 = num_bins[i+1][2:]\n",
    "\n",
    "            pv = st.chi2_contingency([x1,x2])[1]\n",
    "\n",
    "            pvs.append(pv)\n",
    "\n",
    "\n",
    "        i = pvs.index(max(pvs))\n",
    "        num_bins[i:i+2] = [(\n",
    "            num_bins[i][0],\n",
    "            num_bins[i+1][1],\n",
    "            num_bins[i][2]+num_bins[i+1][2],\n",
    "            num_bins[i][3]+num_bins[i+1][3])]\n",
    "\n",
    "\n",
    "        bins_df = get_woe(num_bins)\n",
    "        if iv:\n",
    "            print(f\"{X} 分{len(num_bins):2}组 IV 值: \",get_iv(bins_df))\n",
    "        if detail:\n",
    "            print(bins_df)\n",
    "\n",
    "    return get_woe(num_bins) #, get_iv(bins_df)\n",
    "\n",
    "auto_col_bins = {'FBG':5,\n",
    "                'Age':6,\n",
    "                'MSP':5,\n",
    "                'WHtR':5,\n",
    "                 'Thrombocyte':5,\n",
    "                 'BT':3,\n",
    "                 'BUN':4,\n",
    "                }\n",
    "\n",
    "\n",
    "hand_bins = {\"Dentition\":[0.0,1.0]\n",
    "            ,\"ECG\":[1.0,2.0]\n",
    "             ,\"Symptom\":[0.0,1.0]\n",
    "            }\n",
    "\n",
    "hand_bins = {k:[-np.inf,*v[:-1],np.inf] for k,v in hand_bins.items()}\n",
    "\n",
    "bins_of_col = {}\n",
    " \n",
    "\n",
    " \n",
    "for col in auto_col_bins:\n",
    "    bins_df = graphforbestbin(DF = model_data\n",
    "                             ,X = col\n",
    "                             ,Y = \"label\"\n",
    "                             ,name=col\n",
    "                             ,q=20\n",
    "                            ,n = auto_col_bins[col]\n",
    "                             ,graph=False\n",
    "                             )\n",
    "    bins_list = sorted(set(bins_df[\"min\"]).union(bins_df[\"max\"]))\n",
    "\n",
    "    bins_list[0],bins_list[-1] = -np.inf,np.inf\n",
    "    bins_of_col[col] = bins_list\n",
    "    \n",
    "\n",
    "  \n",
    "bins_of_col.update(hand_bins)\n",
    " \n",
    "bins_of_col\n",
    "\n",
    "def get_woe(df,col,y,bins):\n",
    "    df = df[[col,y]].copy()\n",
    "    df[\"cut\"] = pd.cut(df[col],bins,duplicates = 'drop')\n",
    "    bins_df = df.groupby(\"cut\")[y].value_counts().unstack()\n",
    "    woe = bins_df[\"woe\"] = np.log((bins_df[0]/bins_df[0].sum())/(bins_df[1]/bins_df[1].sum()))\n",
    "    return woe\n",
    "\n",
    "woeall = {}\n",
    "for col in bins_of_col:\n",
    "    woeall[col] = get_woe(model_data,col,\"label\",bins_of_col[col])\n",
    "    \n",
    "woeall\n",
    "\n",
    "model_data.head()\n",
    "\n",
    "\n",
    "model_woe = pd.DataFrame(index=model_data.index)\n",
    " \n",
    "\n",
    "for col in bins_of_col:\n",
    "    model_woe[col] = pd.cut(model_data[col],bins_of_col[col],duplicates='drop').map(woeall[col])\n",
    "    \n",
    "\n",
    "model_woe[\"label\"] = model_data[\"label\"]\n",
    "\n",
    "model_woe.head()\n",
    "\n",
    "mdata_External['gender'].value_counts()\n",
    "mdata_External.drop(['gender',],axis = 1,inplace = True)\n",
    "\n",
    "mdata_External.head()\n",
    "\n",
    "\n",
    "model_woe_External = pd.DataFrame(index=mdata_External.index)\n",
    " \n",
    " \n",
    "\n",
    "for col in bins_of_col:\n",
    "    model_woe_External[col] = pd.cut(mdata_External[col],bins_of_col[col],duplicates='drop').map(woeall[col])\n",
    "\n",
    "\n",
    "model_woe_External[\"label\"] = mdata_External[\"label\"]\n",
    "\n",
    "\n",
    "vali_X_External = model_woe_External.iloc[:,:-1]\n",
    "vali_y_External = model_woe_External.iloc[:,-1]\n",
    "\n",
    "vali_X_External.info()\n",
    "\n",
    "vali_woe = pd.DataFrame(index=vali_data.index)\n",
    " \n",
    "for col in bins_of_col:\n",
    "    vali_woe[col] = pd.cut(vali_data[col],bins_of_col[col],duplicates='drop').map(woeall[col])\n",
    "vali_woe[\"label\"] = vali_data[\"label\"]\n",
    " \n",
    "vali_X = vali_woe.iloc[:,:-1]\n",
    "vali_y = vali_woe.iloc[:,-1]\n",
    "\n",
    "vali_X\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.metrics import accuracy_score as accuracy, roc_auc_score as auc\n",
    "from sklearn.metrics import confusion_matrix, precision_score, accuracy_score,recall_score, f1_score,roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    " \n",
    "lr = LR(class_weight= {0:1,1:16},penalty=\"l2\",solver=\"liblinear\",C=0.5).fit(vali_X,vali_y)\n",
    "\n",
    "lr.score(vali_X,vali_y)\n",
    "lr_result = lr.predict(vali_X)\n",
    "\n",
    "\n",
    "sw = compute_sample_weight(class_weight=None,y=vali_y)\n",
    "lr_cm = confusion_matrix(vali_y, lr_result, sample_weight=sw).ravel()\n",
    "\n",
    "print(\"\\tAUC:{}\".format(auc(vali_y,lr.predict_proba(vali_X)[:,1])))\n",
    "\n",
    "print(\"\\tAccuracy:{}\".format(accuracy(vali_y,lr_result)))\n",
    "print(\"\\tRecall:{}\".format(recall_score(vali_y,lr_result)))\n",
    "print(\"\\tf1:{}\".format(f1_score(vali_y, lr_result)))\n",
    "print(\"\\tprecision:{}\".format(precision_score(vali_y, lr_result)))\n",
    "\n",
    "print(lr_cm)\n",
    "\n",
    "lr_result_External = lr.predict(vali_X_External)\n",
    "sw = compute_sample_weight(class_weight=None,y=vali_y_External)\n",
    "lr_cm_External = confusion_matrix(vali_y_External, lr_result_External, sample_weight=sw).ravel()\n",
    "\n",
    "print(\"\\tAUC:{}\".format(auc(vali_y_External,lr.predict_proba(vali_X_External)[:,1])))\n",
    "\n",
    "print(\"\\tAccuracy:{}\".format(accuracy(vali_y_External,lr_result_External)))\n",
    "print(\"\\tRecall:{}\".format(recall_score(vali_y_External,lr_result_External)))\n",
    "print(\"\\tf1:{}\".format(f1_score(vali_y_External, lr_result_External)))\n",
    "print(\"\\tprecision:{}\".format(precision_score(vali_y_External, lr_result_External)))\n",
    "# print(\"roc_auc %f\" % (roc_auc))\n",
    "print(lr_cm_External)\n",
    "\n",
    "lr.get_params() \n",
    "\n",
    "large = 28; med = 20; small = 12\n",
    "params = {'axes.titlesize': med, \n",
    "          'legend.fontsize': 28, \n",
    "          'legend.loc': 'lower right',\n",
    "          #'figure.figsize': (16, 10), \n",
    "          'axes.labelsize': 28, \n",
    "          'xtick.labelsize': 28,\n",
    "          'ytick.labelsize': 28,\n",
    "          'figure.titlesize': 28} \n",
    "plt.rcParams.update(params) \n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "FPR, recall, thresholds = roc_curve(vali_y,lr.predict_proba(vali_X)[:,1],pos_label=1)\n",
    "FPR\n",
    "recall\n",
    "thresholds \n",
    "from sklearn.metrics import roc_auc_score as AUC\n",
    "area = AUC(vali_y,lr.predict_proba(vali_X)[:,1])\n",
    "\n",
    "maxindex = (recall - FPR).tolist().index(max(recall - FPR))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,7), dpi= 500)\n",
    "\n",
    "\n",
    "bwith = 3\n",
    "TK = plt.gca()\n",
    "TK.spines['bottom'].set_linewidth(bwith)\n",
    "TK.spines['left'].set_linewidth(bwith)\n",
    "TK.spines['top'].set_linewidth(bwith)\n",
    "TK.spines['right'].set_linewidth(bwith)\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(FPR, recall,color='red',linewidth = 6.0,label='ROC curve (area =  0.8671)' % area)\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='black', linestyle='--')\n",
    "bwith = 1.5 \n",
    "\n",
    "plt.scatter(FPR[maxindex],recall[maxindex],c=\"black\",s=150)\n",
    "plt.text(FPR[maxindex]+0.04,recall[maxindex]-0.01,'(best threshold:'+str('%.2f'%thresholds[maxindex])+')',fontsize=25)\n",
    "print(area)\n",
    "print(thresholds[maxindex])\n",
    "print(FPR[maxindex])\n",
    "print(recall[maxindex])\n",
    "\n",
    "plt.xlim([-0.02,1.02])\n",
    "plt.ylim([-0.02,1.02])\n",
    "font2 = {\n",
    "    'family':'Times New Roman',\n",
    "    'weight':'normal',\n",
    "    'size':35,\n",
    "    'style':'italic'\n",
    "}\n",
    "font1 = {\n",
    "    'family':'Times New Roman',\n",
    "    'weight':'normal',\n",
    "    'size':25\n",
    "}\n",
    "plt.xlabel('1-Specificity',font2)\n",
    "plt.ylabel('Sensitivily',font2)\n",
    "l1 = plt.legend(loc = \"lower right\",fontsize = 25,prop=font1)\n",
    "\n",
    "\n",
    "# 外部验证ROC\n",
    "plt.rcParams['font.sans-serif']=['Simhei'] \n",
    "plt.rcParams['axes.unicode_minus']=False\n",
    "from sklearn.metrics import roc_curve\n",
    "FPR, recall, thresholds = roc_curve(vali_y_External,lr.predict_proba(vali_X_External)[:,1],pos_label=1)\n",
    "FPR\n",
    "recall\n",
    "thresholds \n",
    "from sklearn.metrics import roc_auc_score as AUC\n",
    "area = AUC(vali_y_External,lr.predict_proba(vali_X_External)[:,1])\n",
    "\n",
    "maxindex = (recall - FPR).tolist().index(max(recall - FPR))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,7), dpi= 500)\n",
    "\n",
    "\n",
    "bwith = 3\n",
    "TK = plt.gca()\n",
    "TK.spines['bottom'].set_linewidth(bwith)\n",
    "TK.spines['left'].set_linewidth(bwith)\n",
    "TK.spines['top'].set_linewidth(bwith)\n",
    "TK.spines['right'].set_linewidth(bwith)\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(FPR, recall,color='red',linewidth = 6.0,label='ROC curve (area =  0.824)' % area)\n",
    "\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='black', linestyle='--')\n",
    "bwith = 1.5 \n",
    "\n",
    "plt.scatter(FPR[maxindex],recall[maxindex],c=\"black\",s=150)\n",
    "plt.text(FPR[maxindex]+0.04,recall[maxindex]-0.01,'(best threshold:'+str('%.2f'%thresholds[maxindex])+')',fontsize=25)\n",
    "print(area)\n",
    "print(thresholds[maxindex])\n",
    "print(FPR[maxindex])\n",
    "print(recall[maxindex])\n",
    "\n",
    "plt.xlim([-0.02,1.02])\n",
    "plt.ylim([-0.02,1.02])\n",
    "font2 = {\n",
    "    'family':'Times New Roman',\n",
    "    'weight':'normal',\n",
    "    'size':35,\n",
    "    'style':'italic'\n",
    "}\n",
    "font1 = {\n",
    "    'family':'Times New Roman',\n",
    "    'weight':'normal',\n",
    "    'size':25\n",
    "}\n",
    "plt.xlabel('1-Specificity',font2)\n",
    "plt.ylabel('Sensitivily',font2)\n",
    "l1 = plt.legend(loc = \"lower right\",fontsize = 25,prop=font1)\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.sans-serif']=['Simhei'] \n",
    "plt.rcParams['axes.unicode_minus']=False\n",
    "file = \"./chdscorecardfemale.csv\"\n",
    "X.drop(['gender',],axis = 1,inplace = True)\n",
    "\n",
    "base_score = (48.94 - 8.094*lr.intercept_)\n",
    "with open(file,\"w\") as fdata:\n",
    "    base_score = round(base_score[0],1)\n",
    "    mdata.write(\"base_score,{}\\n\".format(base_score,2))\n",
    "for i,col in enumerate(X.columns):\n",
    "    score = round((((woeall[col] * (-B*lr.coef_[0][i]))))/3.95,2)\n",
    "    score.name = \"Score\"\n",
    "    score.index.name = col\n",
    "    score.to_csv(file,header=True,mode=\"a\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
